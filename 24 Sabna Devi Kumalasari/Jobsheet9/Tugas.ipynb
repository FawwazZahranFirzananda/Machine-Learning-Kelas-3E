{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TUGAS**\n",
    "- Avifah Dwi Cahyani (2141720053)\n",
    "- Sabna Devi Kumalasari (2141720009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lakukan klasifikasi pada data MNIST dengan menggunakan model ANN\n",
    "- Anda diperbolehkan melakukan eksplorasi terhadap,\n",
    "    - Metode pra pengolahan\n",
    "    - Pemilihan fitur\n",
    "    - Arsitektur ANN\n",
    "    - Fungsi Aktiviasi\n",
    "- ANN diimplementasikan dengan menggunakan **tensorflow**.\n",
    "- DIKERJAKAN SECARA BERKELOMPOK\n",
    "- JELASKAN HASIL YANG ANDA DAPATKAN,\n",
    "    - AKURASI\n",
    "    - CONFUSION MATRIX\n",
    "    - KONFIGURASI MODEL --> MULAI DARI PRA PENGOLAHAN SAMPAI ARSITEKTUR ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "Import Library dan Persiapan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WINDOWS 10\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Unduh dataset MNIST dari scikit-learn\n",
    "mnist = fetch_openml('mnist_784')\n",
    "\n",
    "# Pisahkan data gambar dan label\n",
    "images = mnist.data.astype('float32')\n",
    "labels = mnist.target.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah 1 pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images /= 255.0  # Skalakan data\n",
    "\n",
    "# Bagi data menjadi data pelatihan dan pengujian\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah 2 Definisikan arsitektur model ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Reshape(target_shape=(28, 28, 1), input_shape=(784,)), #engubah bentuk input dari vektor 1D (784 elemen) menjadi matriks 3D (28x28x1). \n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)), #Menambahkan lapisan konvolusi dengan 32 filter, masing-masing berukuran 3x3, dan fungsi aktivasi ReLU.\n",
    "    layers.MaxPooling2D((2, 2)), #Menambahkan lapisan max pooling dengan ukuran jendela 2x2.\n",
    "    layers.Flatten(), #Mengubah output dari lapisan sebelumnya (berupa matriks) menjadi vektor 1D.\n",
    "    layers.Dense(128, activation='relu'), #Menambahkan lapisan terhubung penuh (fully connected) dengan 128 neuron dan fungsi aktivasi ReLU.\n",
    "    layers.Dense(64, activation='relu'), #Menambahkan lapisan terhubung penuh dengan 64 neuron dan fungsi aktivasi ReLU.\n",
    "    layers.Dense(10, activation='softmax') #Menambahkan lapisan terhubung penuh dengan 10 neuron (sesuai dengan jumlah kelas digit) dan fungsi aktivasi softmax.\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode ini mendefinisikan struktur model CNN untuk pengenalan digit tulisan tangan. Model ini memiliki lapisan konvolusi, max pooling, dan lapisan terhubung penuh untuk memproses data gambar MNIST. Fungsi aktivasi ReLU digunakan di sebagian besar lapisan, dan pada lapisan terakhir menggunakan softmax untuk mendapatkan probabilitas kelas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah 3 Kompilasi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', #mengoptimalkan proses pelatihan\n",
    "              loss='sparse_categorical_crossentropy', # Memilih fungsi kerugian untuk masalah klasifikasi dengan banyak kelas.\n",
    "              metrics=['accuracy']) #Menggunakan metrik akurasi untuk memantau kinerja model selama proses pelatihan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah 4 Latih model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1400/1400 [==============================] - 29s 19ms/step - loss: 0.8351 - accuracy: 0.7280 - val_loss: 0.3914 - val_accuracy: 0.8877\n",
      "Epoch 2/10\n",
      "1400/1400 [==============================] - 25s 18ms/step - loss: 0.3484 - accuracy: 0.8958 - val_loss: 0.3027 - val_accuracy: 0.9094\n",
      "Epoch 3/10\n",
      "1400/1400 [==============================] - 25s 18ms/step - loss: 0.2704 - accuracy: 0.9180 - val_loss: 0.2443 - val_accuracy: 0.9255\n",
      "Epoch 4/10\n",
      "1400/1400 [==============================] - 26s 18ms/step - loss: 0.2156 - accuracy: 0.9348 - val_loss: 0.1991 - val_accuracy: 0.9383\n",
      "Epoch 5/10\n",
      "1400/1400 [==============================] - 26s 19ms/step - loss: 0.1785 - accuracy: 0.9458 - val_loss: 0.1778 - val_accuracy: 0.9462\n",
      "Epoch 6/10\n",
      "1400/1400 [==============================] - 26s 19ms/step - loss: 0.1560 - accuracy: 0.9522 - val_loss: 0.1551 - val_accuracy: 0.9529\n",
      "Epoch 7/10\n",
      "1400/1400 [==============================] - 26s 19ms/step - loss: 0.1390 - accuracy: 0.9574 - val_loss: 0.1468 - val_accuracy: 0.9551\n",
      "Epoch 8/10\n",
      "1400/1400 [==============================] - 26s 19ms/step - loss: 0.1268 - accuracy: 0.9611 - val_loss: 0.1364 - val_accuracy: 0.9583\n",
      "Epoch 9/10\n",
      "1400/1400 [==============================] - 26s 18ms/step - loss: 0.1166 - accuracy: 0.9633 - val_loss: 0.1347 - val_accuracy: 0.9593\n",
      "Epoch 10/10\n",
      "1400/1400 [==============================] - 26s 18ms/step - loss: 0.1086 - accuracy: 0.9665 - val_loss: 0.1295 - val_accuracy: 0.9599\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels,\n",
    "                    epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode ini memulai proses pelatihan pada model jaringan saraf dengan menggunakan data latih dari dataset MNIST. Proses ini akan berlangsung selama 10 epoha, dan akan ada evaluasi pada data validasi setiap akhir epoha. Informasi tentang hasil pelatihan akan disimpan dalam variabel history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah 5: Evaluasi model pada data pengujian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 3s 6ms/step - loss: 0.1341 - accuracy: 0.9586\n",
      "Akurasi pada data pengujian: 0.96\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Akurasi pada data pengujian: {test_acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode ini mengukur kinerja model pada data uji setelah proses pelatihan selesai. Hasilnya adalah akurasi model pada data uji. Akurasi adalah rasio prediksi benar terhadap total predik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 10s 6ms/step - loss: 0.1044 - accuracy: 0.9676\n",
      "Akurasi pada data pelatihan: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi akurasi data pelatihan\n",
    "train_loss, train_acc = model.evaluate(train_images, train_labels)\n",
    "print(f'Akurasi pada data pelatihan: {train_acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode ini mengukur kinerja model pada data latih setelah proses pelatihan selesai. Hasilnya adalah akurasi model pada data latih. Akurasi adalah rasio prediksi benar terhadap total prediksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 2s 5ms/step\n",
      "Matriks Kebingungan:\n",
      "[[1312    1    6    0    2    5    3    2    8    4]\n",
      " [   0 1566    8    5    3    0    1    3   11    3]\n",
      " [   8    7 1315    5    7    4    4   10   16    4]\n",
      " [   3    5   13 1332    1   21    2   12   30   14]\n",
      " [   1    0    3    2 1260    1    2    1    2   23]\n",
      " [   4    2    1   15    6 1195   15    0   28    7]\n",
      " [   7    3    2    0   10   10 1356    0    7    1]\n",
      " [   2    4    8    2    6    2    1 1452    1   25]\n",
      " [   7   10   10   11    6    2    4    6 1296    5]\n",
      " [   5    4    1    8   36    2    0   18   10 1336]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Membuat prediksi pada data pengujian\n",
    "predictions = model.predict(test_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Membuat matriks kebingungan\n",
    "confusion = confusion_matrix(test_labels, predicted_labels)\n",
    "print('Matriks Kebingungan:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode ini menghasilkan dan mencetak matriks kebingungan dari hasil prediksi model pada data uji."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
