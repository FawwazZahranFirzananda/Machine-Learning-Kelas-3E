{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praktikum 4 - Klasifikasi dengan ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pra Pengolahan Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langkah 1 - Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\__init__.py:169: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langkah 2 - Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset/Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cek Data (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langkah 3 - Encoding Data Kategorikal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cek Data (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 0 ... 1 1 101348.88]\n",
      " [608 'Spain' 0 ... 0 1 112542.58]\n",
      " [502 'France' 0 ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 0 ... 0 1 42085.58]\n",
      " [772 'Germany' 1 ... 1 0 92888.52]\n",
      " [792 'France' 0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langkah 4 - Encoding Kolom \"Geography\" dengan One Hot Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "1. from sklearn.compose import ColumnTransformer - This line imports the ColumnTransformer class from scikit-learn. The ColumnTransformer is a useful tool for applying different transformations to different columns of a dataset.\n",
    "2. from sklearn.preprocessing import OneHotEncoder - This line imports the OneHotEncoder class from scikit-learn. The OneHotEncoder is a transformer used to convert categorical variables into a binary one-hot encoded representation.\n",
    "3. ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough') - This line creates an instance of ColumnTransformer called ct. The transformers argument specifies the transformations to be applied. In this case, a tuple is provided with the name 'encoder', an instance of OneHotEncoder(), and the index [1], which indicates that the one-hot encoding transformation should be applied to the column at index 1 of the dataset. The remainder='passthrough' argument indicates that any remaining columns in the dataset should be passed through without any transformation.\n",
    "4. X = np.array(ct.fit_transform(X)) - This line applies the transformation defined by the ColumnTransformer (ct) to the input dataset X. The fit_transform method is used to fit the transformer to the data and apply the transformation. The resulting transformed dataset is assigned back to the variable X, which is then converted to a NumPy array using np.array()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cek Data (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
      " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
      " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
      " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
      " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langkah 5 - Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langkah 6 - Scaling Fitur**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat Model ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langkah 1 - Inisiasi Model ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "Initializes a sequential model in Keras using tf.keras.models.Sequential(). The Sequential model is a linear stack of layers, where we can easily add layers one by one. It is a commonly used model in Keras for building neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langkah 2 - Membuat Input Layer dan Hidden Layer Pertama**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "Adds a new Dense layer to the existing sequential model (ann), with 6 units and a ReLU activation function. By adding this layer, we are introducing another hidden layer to the neural network. Each Dense layer represents a fully connected layer, where each neuron is connected to every neuron in the previous layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langkah 3 - Membuat Hidden Layer Kedua**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: This line code has the same code as the previous code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langkah 4 - Membuat Output Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: Adds a new Dense layer to the existing sequential model (ann), with 1 unit and a sigmoid activation function. By adding this layer, we are introducing the output layer of the neural network. The output layer typically contains a single neuron for binary classification tasks, where the goal is to predict one of two classes. The units parameter is set to 1, indicating that the output layer has one neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langkah 1 - Compile Model (Menyatukan Arsitektur) ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "1. optimizer='adam' - This parameter specifies the optimizer to be used for updating the weights of the neural network during training. In this case, the Adam optimizer is used, which is a popular optimizer that adapts the learning rate based on the gradient of the parameters.\n",
    "2. loss='binary_crossentropy' - This parameter specifies the loss function to be minimized during training. It is appropriate when dealing with binary classification problems, where the goal is to predict one of two classes.\n",
    "3. metrics=['accuracy'] - This parameter specifies the evaluation metric to be used during training and evaluation. In this case, the accuracy metric is used, which calculates the proportion of correctly classified samples.\n",
    "\n",
    "After compiling the model, it is ready to be trained on the training data using the fit method, where we would specify the input data (X_train) and corresponding target labels (y_train)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langkah 2 - Fitting Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 2ms/step - loss: 0.7345 - accuracy: 0.5176\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7952\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4614 - accuracy: 0.8035\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4317 - accuracy: 0.8129\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4142 - accuracy: 0.8209\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3993 - accuracy: 0.8279\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8369\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8422\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8460\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3624 - accuracy: 0.8490\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8506\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8537\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3542 - accuracy: 0.8535\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3525 - accuracy: 0.8556\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8560\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.8562\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8569\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8577\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3484 - accuracy: 0.8575\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8566\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8583\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8596\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8595\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3455 - accuracy: 0.8579\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8602\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8590\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8590\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8591\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8587\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8595\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8601\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3431 - accuracy: 0.8576\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3424 - accuracy: 0.8581\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8593\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8589\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3419 - accuracy: 0.8583\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8601\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8589\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3410 - accuracy: 0.8600\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3408 - accuracy: 0.8605\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8600\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8601\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3404 - accuracy: 0.8605\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3400 - accuracy: 0.8601\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3400 - accuracy: 0.8604\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8600\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3399 - accuracy: 0.8608\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8600\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3392 - accuracy: 0.8624\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8620\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8608\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8614\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8614\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8609\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8621\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8614\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8608\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8606\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8614\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8622\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8619\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3379 - accuracy: 0.8626\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8624\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8620\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8625\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8637\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8621\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8627\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8645\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8629\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8621\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8626\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8615\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8614\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3366 - accuracy: 0.8643\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8625\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8631\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8626\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8629\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8615\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8625\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8624\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8629\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8635\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8619\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8631\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3359 - accuracy: 0.8627\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8625\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8629\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8620\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8615\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8624\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8616\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8619\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8625\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8621\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8620\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3348 - accuracy: 0.8620\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8640\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21dff2da6e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "1. batch_size=32 - This parameter specifies the number of samples used in each batch for weight updates. The training data is divided into smaller batches, and the model is updated after processing each batch.\n",
    "2. epochs=100 - This parameter specifies the number of times the model will iterate over the entire training dataset during the training process. Each iteration over the entire dataset is called an epoch. By specifying 100 epochs, the model will go through the training data 100 times, updating the weights and improving its performance.\n",
    "\n",
    "During the training process, the model will learn to make predictions based on the input data and adjust its weights using the optimizer and loss function specified during compilation. The goal is to minimize the loss function and improve the model's accuracy on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat Prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelkan Data Baru dan Buat Prediksi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 127ms/step\n",
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "1. ann.predict(...) - This part of the code uses the trained model (ann) to make predictions on the transformed input example. The predict method takes the transformed input example as its argument and returns the predicted output.\n",
    "2. The code transforms the input example using the scaler, passes the transformed example to the trained model for prediction, and prints whether the prediction is greater than 0.5 or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apakah hasilnya **False**?\n",
    "Benar, hasilnya adalah False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediksi Dengan Data Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "1. print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)) - This line concatenates the reshaped predicted labels (y_pred) and the reshaped actual labels (y_test) using np.concatenate. The reshape function is used to ensure that the arrays have the same shape before concatenation.\n",
    "2. This code can help us evaluate the performance of the model by comparing the predicted labels with the ground truth labels on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cek Akurasi dan Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1521   74]\n",
      " [ 197  208]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8645"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "1. cm = confusion_matrix(y_test, y_pred) - This line computes the confusion matrix by comparing the actual labels (y_test) with the predicted labels (y_pred). The confusion matrix is a table that summarizes the performance of a classification model by counting the number of true positives, true negatives, false positives, and false negatives. The resulting confusion matrix is stored in the variable cm.\n",
    "2. accuracy_score(y_test, y_pred) - This line computes the accuracy score by comparing the actual labels (y_test) with the predicted labels (y_pred). The accuracy score is a metric that measures the proportion of correctly classified examples out of the total number of examples. The resulting accuracy score is printed using print().\n",
    "3. The confusion matrix provides a detailed breakdown of the model's predictions, while the accuracy score gives a single metric indicating the overall accuracy of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
