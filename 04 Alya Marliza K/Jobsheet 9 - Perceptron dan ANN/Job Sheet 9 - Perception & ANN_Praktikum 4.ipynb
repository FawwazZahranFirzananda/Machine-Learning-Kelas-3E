{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Praktikum 4**\n",
    "\n",
    "Klasifikasi dengan ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deskripsi**\n",
    "\n",
    "\n",
    "Pada praktikum kali ini, Anda diminta untuk membuat model ANN untuk mengklasifikasi potensi seorang customer akan meninggalkan perusahaan Anda atau tidak. Istirlah populer dari fenomena ini disebut sebagai 'churn'. Tingkat churn yang tinggi (chrun rate) akan berdampak tidak baik bagi perusahaan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠ **Perhatian!** ⚠\n",
    "\n",
    "Pada praktikum ini, Anda akan menggunakan library tensorflow dari google. Oleh karena itu, Anda diharuskan untuk menginstal tensorflow terlebih dahulu.\n",
    "Anda juga perlu menyesuaikan instalasi tensorflow yang Anda gunakan pada komputer lokal, apakah komputasi pada,\n",
    "* CPU\n",
    "* GPU (GPU support CUDA)\n",
    "* Apple Silicon (M1/M2)\n",
    "\n",
    "Panduan instalasi,\n",
    "\n",
    "* https://www.tensorflow.org/install\n",
    "* https://developer.apple.com/metal/tensorflow-plugin/\n",
    "* https://caffeinedev.medium.com/how-to-install-tensorflow-on-m1-mac-8e9b91d93706"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pra Pengolahan Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Langkah 1 - Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Mengimpor pustaka NumPy ke dalam program yang dimana library ini berfungsi untuk komputasi numerik dalam pengolahan data dan array.\n",
    "import pandas as pd # Mengimpor pustaka Pandas ke dalam program yang dimana library ini berfungsi untuk memanipulasi dan analisis data tabular.\n",
    "import tensorflow as tf # mengimpor pustaka TensorFlow ke dalam program Python yang digunakan untuk mengembangkan dan melatih model pembelajaran mesin, terutama dalam konteks pembelajaran mendalam (deep learning) dan jaringan saraf (neural networks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Langkah 2 - Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv') # Mengimpor dataset dari file CSV 'Churn_Modelling.csv' ke dalam dataframe menggunakan library pandas (pd).\n",
    "X = dataset.iloc[:, 3:-1].values # Mengambil subset dari dataset, yaitu kolom 3 hingga kolom sebelum terakhir, dan mengonversinya menjadi array NumPy.\n",
    "y = dataset.iloc[:, -1].values # Mengambil kolom terakhir dari dataset dan mengonversinya menjadi array NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cek data (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X) # Untuk mencetak data (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Langkah 3 - Encoding Data Kategorikal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cek data (X) dengan print. Hasilnya,\n",
      "[[619 'France' 0 ... 1 1 101348.88]\n",
      " [608 'Spain' 0 ... 0 1 112542.58]\n",
      " [502 'France' 0 ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 0 ... 0 1 42085.58]\n",
      " [772 'Germany' 1 ... 1 0 92888.52]\n",
      " [792 'France' 0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "hasil = (\"Cek data (X) dengan print. Hasilnya,\")\n",
    "print (hasil)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder # Mengimpor pustaka LabelEncoder dari scikit-learn, yang digunakan untuk mengkodekan (mengubah) label kategori menjadi angka.\n",
    "le = LabelEncoder() # Membuat objek LabelEncoder yang akan digunakan untuk melakukan transformasi label kategori.\n",
    "X[:, 2] = le.fit_transform(X[:, 2]) # Mengambil kolom ke-2 dari matriks X (data fitur) dan mengubah label kategori dalam kolom tersebut menjadi angka menggunakan LabelEncoder yang telah dibuat sebelumnya.\n",
    "print(X) # Untuk mencetak data (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Langkah 4 - Encoding Kolom \"Geography\" dengan One Hot Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cek data (X) dengan print. Hasilnya,\n",
      "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
      " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
      " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
      " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
      " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "hasil = (\"Cek data (X) dengan print. Hasilnya,\")\n",
    "print (hasil)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer # Mengimpor pustaka ColumnTransformer dari scikit-learn, yang digunakan untuk mengubah data dalam kolom tertentu.\n",
    "from sklearn.preprocessing import OneHotEncoder # Mengimpor pustaka OneHotEncoder dari scikit-learn, yang digunakan untuk mengkodekan variabel kategoris menjadi vektor biner.\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough') # Membuat objek ColumnTransformer untuk mengubah kolom ke-1 dalam data menjadi representasi one-hot encoding dan menjaga kolom-kolom lainnya tidak berubah (\"passthrough\").\n",
    "X = np.array(ct.fit_transform(X)) # Menggunakan ColumnTransformer untuk mengubah data X, sehingga kolom ke-1 telah di-encode menggunakan one-hot encoding, dan kolom lainnya tetap tidak berubah (passthrough). Data hasil transformasi disimpan kembali dalam X.\n",
    "\n",
    "print (X) # Untuk mencetak data (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Langkah 5 - Split Data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengimpor fungsi train_test_split dari pustaka scikit-learn. Fungsi ini digunakan untuk membagi data menjadi subset pelatihan dan pengujian.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Menggunakan fungsi train_test_split untuk membagi data menjadi data pelatihan (X_train, y_train) dan data pengujian (X_test, y_test). \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Langkah 6 - Scaling Fitur**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # Mengimpor pustaka scikit-learn untuk penskalaan data.\n",
    "sc = StandardScaler() # Membuat objek penskalaan data dengan metode StandarScaler. \n",
    "\n",
    "X_train = sc.fit_transform(X_train) # Menskala data pelatihan (X_train) sehingga memiliki rata-rata nol dan deviasi standar satu (standarisasi).\n",
    "X_train = sc.fit_transform(X_train) # Menskala data pengujian (X_test) dengan parameter yang sama seperti yang digunakan pada data pelatihan. Hal ini memastikan data pengujian diperlakukan dengan cara yang sama seperti data pelatihan.\n",
    "X_test = sc.transform(X_test) # Mentransformasi (normalisasi) data pengujian X_test menggunakan objek Scaler (sc) yang telah dipelajari dari data pelatihan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Membuat Model ANN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Langkah 1 - Inisiasi Model ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential() # Membuat model jaringan saraf tiruan (ANN) menggunakan TensorFlow dengan arsitektur berurutan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Langkah 2 - Membuat Input Layer dan Hidden Layer Pertama**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu')) #  Menambahkan lapisan Dense (fully connected) dengan 6 unit neuron dan fungsi aktivasi ReLU ke dalam model ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Langkah 3 - Membuat Hidden Layer Kedua**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu')) # Menambahkan lapisan Dense kedua dengan 6 unit neuron dan fungsi aktivasi ReLU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Langkah 4 - Membuat Output Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) # Menambahkan lapisan Dense terakhir dengan 1 unit neuron dan fungsi aktivasi sigmoid. Ini digunakan untuk output biner (0 atau 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Langkah 1 - Compile Model (Menyatukan Arsitektur) ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) # Mengompilasi model dengan pengaturan seperti pengoptimalan menggunakan 'adam', pengukuran kesalahan menggunakan 'binary_crossentropy' untuk masalah klasifikasi biner, dan pengukuran metrik akurasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Langkah 2 - Fitting Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.7533\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4830 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4565 - accuracy: 0.7960\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4416 - accuracy: 0.7965\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8049\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8154\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8238\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8276\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8300\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8317\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8321\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8329\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8331\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8341\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8334\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8353\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8460\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8506\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8525\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8541\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8559\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3547 - accuracy: 0.8568\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8564\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8586\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8579\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8600\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8605\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3494 - accuracy: 0.8593\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8610\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8601\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8604\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3473 - accuracy: 0.8597\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8609\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8612\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.8608\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8616\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8601\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8626\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8604\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3433 - accuracy: 0.8589\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8616\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8610\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8614\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8620\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8604\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3418 - accuracy: 0.8622\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3407 - accuracy: 0.8616\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8631\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3408 - accuracy: 0.8622\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8624\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3406 - accuracy: 0.8636\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3400 - accuracy: 0.8620\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3398 - accuracy: 0.8626\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3395 - accuracy: 0.8624\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8641\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3394 - accuracy: 0.8627\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3388 - accuracy: 0.8622\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8614\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8634\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3382 - accuracy: 0.8619\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3383 - accuracy: 0.8609\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8633\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8622\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8633\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3375 - accuracy: 0.8637\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8618\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8629\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3374 - accuracy: 0.8639\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3365 - accuracy: 0.8639\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8619\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8626\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3364 - accuracy: 0.8639\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8626\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3360 - accuracy: 0.8650\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3363 - accuracy: 0.8636\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3361 - accuracy: 0.8640\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8635\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8624\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8629\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8640\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.8633\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8634\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8636\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8649\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.8626\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8639\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8636\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8634\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8637\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8636\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8637\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8629\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8630\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8645\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3338 - accuracy: 0.8641\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3340 - accuracy: 0.8655\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8618\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8633\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3336 - accuracy: 0.8630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20f99a09b10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100) # Melatih model ANN dengan data pelatihan X_train dan label y_train. Ini dilakukan selama 100 iterasi (epochs) dengan ukuran batch sebesar 32. Tujuannya adalah untuk mengoptimalkan model untuk melakukan tugas klasifikasi yang sesuai dengan data pelatihan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Membuat Prediksi**\n",
    "\n",
    "Diberikan informasi sebagai berikut,\n",
    "\n",
    "* Geography: France\n",
    "* Credit Score: 600\n",
    "* Gender: Male\n",
    "* Age: 40 years old\n",
    "* Tenure: 3 years\n",
    "* Balance: $ 60000\n",
    "* Number of Products: 2\n",
    "* Does this customer have a credit card ? Yes\n",
    "* Is this customer an Active Member: Yes\n",
    "* Estimated Salary: $ 50000\n",
    "\n",
    "Apakah customer tersebut perlu dipertahankan?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modelkan Data Baru dan Buat Prediksi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step\n",
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "# menghasilkan prediksi dari model jaringan saraf tiruan (neural network) untuk data masukan yang telah diubah skala, dan kemudian memeriksa apakah hasil prediksi lebih besar dari 0.5.\n",
    "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apakah hasilnya **False**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prediksi Dengan Data Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test) # Menghasilkan prediksi model untuk data uji.\n",
    "y_pred = (y_pred > 0.5) # mengonversi prediksi model ke dalam bentuk boolean, yaitu True jika nilai prediksi lebih besar dari 0.5, dan False sebaliknya.\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)) #  Ini mencetak prediksi model dan label sebenarnya untuk data uji dalam satu baris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cek Akurasi dan Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1508   87]\n",
      " [ 195  210]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.859"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil = (\"Hasil (bisa jadi berbeda),\")\n",
    " \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score # Mengimpor modul untuk menghitung matriks kebingungan (confusion matrix) dan akurasi model.\n",
    "cm = confusion_matrix(y_test, y_pred) # Menghitung matriks kebingungan berdasarkan prediksi model dan label sebenarnya dari data uji.\n",
    "print(cm) # mencetak (print) matriks kebingungan (confusion matrix) ke layar. Matriks ini digunakan untuk mengevaluasi performa model klasifikasi dengan melihat sejauh mana model benar dan salah dalam mengklasifikasikan data.\n",
    "accuracy_score(y_test, y_pred) # Menghitung akurasi model dengan membandingkan prediksi dengan label sebenarnya pada data uji."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
