{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w9n4avARm_mN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf # untuk membangun dan melatih jaringan saraf tiruan serta menjalankan komputasi numerik dengan efisien.\n",
        "import numpy as np # untuk menyediakan struktur data array multidimensi yang efisien dan berbagai fungsi matematika yang kuat. \n",
        "import os # untuk berinteraksi dengan sistem operasi. \n",
        "import time # untuk mengukur waktu "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urzp-ryonH2u",
        "outputId": "42facb22-aa16-4822-b85a-914eb93acfe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# untuk mengunduh file dari URL\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elSqho_gnPP-",
        "outputId": "a853e1fe-2a41-4905-de3b-58d8227ddb40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Xw9MP7nQLe",
        "outputId": "4c1077d6-0b89-48eb-fbca-3ab3b0d6ac48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0GJyPdmnSsZ",
        "outputId": "a010d4cd-5877-4588-8dc5-abbbc18fe2cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text)) # untuk membuat himpunan (set) karakter unik dari teks\n",
        "print(f'{len(vocab)} unique characters') # mencetak jumlah karakter unik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbRDOPYLnU1t",
        "outputId": "4a5c9d0a-73d3-47fe-9723-4dbb080fbbba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_texts = ['abcdefg', 'xyz'] # mendefinisikan sebuah list yang berisi beberapa teks contoh\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8') # membagi teks menjadi karakter unicode dan untuk menentukan encoding input\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zSHlnQdCnbkY"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup( # membuat objek dan digunakan untuk mengonversi karakter menjadi ID\n",
        "vocabulary=list(vocab), mask_token=None) # diberikan list karakter unik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yCbWUoxnfDn",
        "outputId": "86f01435-955b-4fac-d87b-924ac7623b4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids = ids_from_chars(chars) # mengonversi karakter unicode\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ibx0CPJCnjjB"
      },
      "outputs": [],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup( # mengonversi ID kembali menjadi karakter\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None) # konversi akan dilakukan dari ID menjadi karakter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jjr0W4BlnmdO",
        "outputId": "6ccc20ae-4f57-4160-bf22-c01e2e7bbb01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chars = chars_from_ids(ids) # ntuk mengonversi ID (yang disimpan dalam variabel ids) kembali menjadi karakter-karakter unicode.\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICfs9emRnp4J",
        "outputId": "8849ceff-f359-4263-967f-de92f3f3faeb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy() # menggabungkan karakter-karakter unicode menjadi sebuah string menggunakan fungsi dan mengembalikan hasilnya dalam bentuk array NumPy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LebC7R0Vnq38"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids): # mengonversi ID menjadi karakter-karakter unicode.\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1) # menggabungkan karakter-karakter unicode yang dihasilkan dari konversi ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRKgvBB4nsV5",
        "outputId": "982f3e96-9e99-4114-eb96-44398fadca31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# mengonversi teks dan membagi teks menjadi karakter-karakter unicode.\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1Z5TUoWCn2V0"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids) # sumber data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KKfz4F4n4AN",
        "outputId": "f5a3fa16-812c-4496-c815-e41a342c6dce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10): # perulangan untuk mengiterasi 10 barus dan digunakan untuk membatasai jumlah baris yang diambil\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8')) # mengonversi array NumPy menjadi string menggunakan encoding UTF-8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "STXls0Xrn7ot"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul27p1-7n_GP",
        "outputId": "0ac67f0c-d349-49b6-9302-77e04230aa4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True) # membuat sekumpulan urutan\n",
        "\n",
        "for seq in sequences.take(1): # perulangan untuk mengiterasi melalui satu sekumpulan \n",
        "  print(chars_from_ids(seq)) # mencetak karakter unicode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MP0Zj8ToBAt",
        "outputId": "fb83de10-ba53-4d40-d715-53b69050beba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5): # perualangan untuk mengiterasi melalui 5 sekumpulan urutan\n",
        "    print(text_from_ids(seq).numpy()) # mengonversi setiap urutan menjadi string lalu dicetak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Sd00xFknoCeb"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence): # mendefinisikan fungsi yang akan membagi urutan menjadi teks input dan teks target\n",
        "  input_text = sequence[:-1] # mengambil semua elemen kecuali elemen terakhir yg digunakan sebagai teks input\n",
        "  target_text = sequence[1:] # mengambil semua elemen kecuali elemen terakhir yg digunakan sebagai teks target\n",
        "  return input_text, target_text # mengembalikan teks input dan teks target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGLGIE2-oNLj",
        "outputId": "fc31e76a-0bdc-44ea-d24c-af2933178948"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\")) # membagi urutan menjadi teks input (baris atas) dan teks target (baris bawah )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uh76vs_CoO0K"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target) # pemetaan menggunakan fungsi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0TTTeAgoR24",
        "outputId": "60ebe0c2-1af6-4f02-ef26-33549f0f98e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1): # perulangan untuk mengiterasi elemen dan digunakan untuk mengambil satu elemen pertama dari dataset\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy()) # mencetak teks dari input_example\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy()) # mencetak teks dari target_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq6j-8ploXvf",
        "outputId": "249d6de1-500c-4c6b-962b-5933bfbec585"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# menentukan ukuran batch yg akan digunakan dalam pelatihan\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000 # menentukan ukuran buffer yg akan digunakan dalam pengacakan\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE) # metode shuffle untuk mengacak elemen dalam dataset\n",
        "    .batch(BATCH_SIZE, drop_remainder=True) # untuk membagi dataset menjadi batch yg lebih kecil\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)) # memuat data secara asinkron pada saat pelatihan\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8uDDdszkobHC"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "algaAI7QodJn"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units): # metode yang akan menerima 3 argumen\n",
        "    super().__init__(self) # pemanggilan konstruktor dari kelas induk\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) # mengubah bilangan integer menjadi vektor\n",
        "    # lapisan GRU akan mengembalikan urutan keluaran untuk setiap langkah waktu dan akan mengembalikan keadaan internal pada langkah waktu terakhir\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size) # menghasilkan output model\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False): # mendefinisikan bagaimana model akan melakukan komputasi saat dipanggil\n",
        "    x = inputs # Variabel x diinisialisasi dengan nilai inputs\n",
        "    x = self.embedding(x, training=training) # Input x dilewatkan melalui lapisan embedding untuk menghasilkan vektor embedding\n",
        "    # Jika states tidak diberikan (yaitu pada langkah waktu pertama), maka get_initial_state dari lapisan GRU digunakan untuk mendapatkan keadaan internal awal.\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training) # Input x dan keadaan internal states dilewatkan melalui lapisan GRU\n",
        "    x = self.dense(x, training=training) # Keluaran x dari lapisan GRU dilewatkan melalui lapisan Dense untuk menghasilkan output model.\n",
        "\n",
        "    # jika bernilai True, maka model akan mengembalikan output x dan keadaan internal states.\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    \n",
        "    # jika bernilai False, maka model akan mengembalikan hanya output x.\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "veXPNF62oetg"
      },
      "outputs": [],
      "source": [
        "model = MyModel( # membuat objek model\n",
        "    vocab_size=vocab_size, # argumen yang diberikan ke parameter vocab_size saat membuat objek model. untuk menentukan jumlah kata unik dalam kamus yang akan digunakan dalam model.\n",
        "    embedding_dim=embedding_dim, # argumen yang diberikan ke parameter embedding_dim saat membuat objek model. untuk menentukan dimensi vektor embedding yang akan digunakan dalam model.\n",
        "    rnn_units=rnn_units) # argumen yang diberikan ke parameter rnn_units saat membuat objek model. untuk menentukan jumlah unit RNN yang akan digunakan dalam model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTQFVwrGogrV",
        "outputId": "b097712b-f41e-4997-e92c-135ae3d1091f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1): # untuk mengambil satu batch contoh dari dataset. \n",
        "    example_batch_predictions = model(input_example_batch) # model menerima input_example_batch sebagai input dan menghasilkan prediksi example_batch_predictions.\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\") # bentuk (shape) dari example_batch_predictions dicetak ke layar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGEuA3UzoirX",
        "outputId": "0a86bc87-086c-4cbe-c5a5-c9f0924f801c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# untuk mencetak ringkasan (summary) dari arsitektur model ke konsol.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tdh8obcYol6F"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1) # untuk mengambil sampel indeks dari distribusi prediksi. \n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy() # untuk menghapus dimensi yang tidak perlu dari sampled_indices. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNv4cvjtorDx",
        "outputId": "0541e37e-be67-4f15-feb3-db675266571e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([45, 54, 44, 46, 11, 46,  5, 11, 17, 58, 42, 48, 20,  0, 42,  9, 13,\n",
              "       26, 23, 38,  0, 65, 23, 23, 21, 53,  3, 63,  3, 55, 65, 45, 53,  5,\n",
              "       30, 26, 61, 58, 54, 50, 55, 60, 61, 21, 62, 15, 58, 54, 18, 45, 38,\n",
              "       12,  5, 27, 59, 10,  8, 18, 18, 52, 24, 30, 22, 64,  2, 42, 46, 40,\n",
              "        5, 19, 62, 20, 25, 18, 24, 25, 63, 24, 10, 52, 18, 14, 46, 28, 14,\n",
              "       47, 10, 48, 54, 51, 15, 39, 12, 56, 44, 55, 52, 29, 23, 60])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# array yang berisi indeks-indeks sampel yang diambil dari distribusi prediksi. \n",
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ch5TFTeosBS",
        "outputId": "305c3018-6bf6-4e56-c53f-cf0a2a7e9ecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b\" seem tedious,\\nI'll tell thee what befell me on a day\\nIn this self-place where now we mean to stand.\"\n",
            "\n",
            "Next Char Predictions:\n",
            " b'foeg:g&:DsciG[UNK]c.?MJY[UNK]zJJHn!x!pzfn&QMvsokpuvHwBsoEfY;&Nt3-EEmKQIy cga&FwGLEKLxK3mEAgOAh3iolBZ;qepmPJu'\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy()) # untuk mengonversi tensor input_example_batch[0] menjadi teks.\n",
        "print() # mencetak baris kosong sebagai pemisah antara teks input dan prediksi karakter selanjutnya.\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy()) # untuk mengonversi array sampled_indices menjadi teks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "XNycc73cou4Y"
      },
      "outputs": [],
      "source": [
        "# mendefinisikan fungsi kerugian (loss function) yang akan digunakan dalam pelatihan model.\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KggAsty2oxEH",
        "outputId": "ff563ff2-0e56-4438-b971-944f95358138"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.190308, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions) # fungsi loss digunakan untuk menghitung kerugian antara target_example_batch dan example_batch_predictions.\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\") # mencetak bentuk (shape) dari example_batch_predictions.\n",
        "print(\"Mean loss:        \", example_batch_mean_loss) # mencetak nilai kerugian rata-rata example_batch_mean_loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxLBjhCEozmQ",
        "outputId": "5b751f49-4f15-4cfe-8d37-664dcafe1352"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "66.04314"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy() # menghitung eksponen dari nilai example_batch_mean_loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "CUsMhpRPo1Wg"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss) # Argumen optimizer digunakan untuk menentukan optimizer yang akan digunakan saat melatih model. Argumen loss digunakan untuk menentukan fungsi kerugian yang akan digunakan dalam pelatihan model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "K_or6Yg4o3N8"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "# objek ModelCheckpoint yang digunakan sebagai callback selama pelatihan model. Objek ini akan menyimpan checkpoint selama pelatihan. \n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "iEYEcFnLo4rw"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20 # EPOCHS diatur sebagai 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRbBm-fho7Gx",
        "outputId": "6fcba797-ebc9-4c84-b141-583d72b546f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 965s 6s/step - loss: 2.7189\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 920s 5s/step - loss: 1.9914\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 924s 5s/step - loss: 1.7106\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 961s 6s/step - loss: 1.5479\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 962s 6s/step - loss: 1.4496\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 968s 6s/step - loss: 1.3814\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 959s 6s/step - loss: 1.3292\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 934s 5s/step - loss: 1.2848\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 897s 5s/step - loss: 1.2443\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 922s 5s/step - loss: 1.2042\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 908s 5s/step - loss: 1.1651\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 910s 5s/step - loss: 1.1244\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 915s 5s/step - loss: 1.0804\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 933s 5s/step - loss: 1.0347\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 943s 5s/step - loss: 0.9871\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 956s 6s/step - loss: 0.9370\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 960s 6s/step - loss: 0.8842\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 935s 5s/step - loss: 0.8310\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 948s 5s/step - loss: 0.7796\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 920s 5s/step - loss: 0.7309\n"
          ]
        }
      ],
      "source": [
        "# untuk melatih model dengan dataset yang diberikan, menggunakan jumlah epoch sebanyak nilai EPOCHS yang telah ditentukan sebelumnya, dan menggunakan callback checkpoint_callback yang telah dibuat sebelumnya. \n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "hi0AOdURo92L"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0): # untuk menginisialisasi objek OneStep dengan model yang diberikan\n",
        "    super().__init__()\n",
        "    self.temperature = temperature #  atribut yang menyimpan suhu yang digunakan untuk sampling stokastik\n",
        "    self.model = model # atribut yang menyimpan model yang digunakan untuk generasi teks.\n",
        "    # atribut yang menyimpan fungsi konversi karakter ke ID dan ID ke karakter\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None] # ID yang digunakan untuk mengabaikan token \"[UNK]\" (unknown) saat generasi teks.\n",
        "    sparse_mask = tf.SparseTensor( # masker yang diterapkan pada prediksi untuk mencegah token \"[UNK]\" dari dihasilkan dalam generasi teks. \n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask) #  atribut yang menyimpan masker prediksi sebagai tensor padat (dense tensor) untuk digunakan dalam proses generasi teks.\n",
        "\n",
        "  @tf.function # mengubah metode generate_one_step menjadi graf TensorFlow yang dapat dipercepat untuk meningkatkan efisiensi.\n",
        "  def generate_one_step(self, inputs, states=None): # untuk melakukan generasi teks satu langkah pada suatu waktu.\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8') #  mengubah input teks menjadi urutan karakter Unicode.\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor() # Hasil ID token kemudian dikonversi menjadi tensor.\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "F63zVEj6pC95"
      },
      "outputs": [],
      "source": [
        "# Objek ini dibuat dengan menggunakan model yang diberikan, serta fungsi konversi karakter ke ID (chars_from_ids) dan konversi ID ke karakter (ids_from_chars) yang telah didefinisikan sebelumnya.\n",
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZT4JIFOpF1J",
        "outputId": "209dafc4-f282-4d89-8adc-092ad8779d22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "What, ha? hasty in Vienna.\n",
            "\n",
            "GLOUCESTER:\n",
            "In sort and ne'er then had lost his mennor.\n",
            "\n",
            "BALTHASAR:\n",
            "At what hat hath done all thy sexsidicy,\n",
            "Hast whom thy embracements mine enemies;\n",
            "And, in some reprehend honey-athoraxt, they deny the earth,\n",
            "Our virtues had ever than he is,\n",
            "And they believe, that thou entire, are they\n",
            "not thy amile that must be, 'dial foul hundred prosperate,\n",
            "To step bowels, that, if thou deartiness\n",
            "For serves import, what lies this man that calls\n",
            "A Romanoble to condition much:\n",
            "There's not as highness that must bear me to\n",
            "Left this most now live the single toen,\n",
            "And it do I exple to Englander, and his\n",
            "short shall be her womanies; it is in\n",
            "Your back o' the law in the office; or towards\n",
            "And pieped out the world's vows; and, as they were,\n",
            "Brought down to many mimes; onless, ourselves,\n",
            "Dived with distressy-budly lives;\n",
            "For time shall ward my country's kinsment hangled.\n",
            "'Tis thought the more revave? I have conspired his head;\n",
            "This bastard love, or shall well have heads,\n",
            "Standi \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 8.469339609146118\n"
          ]
        }
      ],
      "source": [
        "start = time.time() # memulai penghitungan waktu untuk mengukur berapa lama waktu yang dibutuhkan \n",
        "states = None # keadaan awal model yang akan digunakan dalam generasi teks. \n",
        "next_char = tf.constant(['ROMEO:']) # karakter awal yang digunakan sebagai input untuk memulai generasi teks.\n",
        "result = [next_char] # daftar yang akan menyimpan urutan karakter yang dihasilkan selama generasi teks.\n",
        "\n",
        "for n in range(1000): # loop yang akan melakukan generasi teks sebanyak 1000 langkah.\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states) # generasi teks\n",
        "  result.append(next_char) # Karakter yang diprediksi selanjutnya ditambahkan ke dalam daftar result.\n",
        "\n",
        "result = tf.strings.join(result) # untuk menggabungkan semua karakter dalam daftar result menjadi satu teks yang lengkap.\n",
        "end = time.time() # menghentikan penghitungan waktu setelah generasi teks selesai.\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80) # mencetak hasil generasi teks.\n",
        "print('\\nRun time:', end - start) # mencetak berapa lama waktu yang dibutuhkan untuk melakukan generasi teks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYTIot-BpHqz",
        "outputId": "7b95d709-5801-4796-c970-9f901a7e1e5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nFor beauty is fam, and ask you hence;\\nOur--ask, Bagab,--anster, how many locks.\\n\\nSecond Conspirator:\\nSo peeves.\\n\\nLEONTES:\\nDo you not resemp\\nTill I came unto these weeds are pawed.\\nIs it the heaven, that all the world as his son abuse,\\nShe might shall dispropht their fulless of either'd son;\\nFor whose corrupt away us no agree?\\nYou\\ngo about it, I will answer that which stain he work\\nThat scorn our subjects may prove a Christian love,\\nAnd get your good opposer, suffer as the does of tume\\nUnto mine ears against the day:\\nO Gresces where he hath a found his son't,\\nwould not the abstance: take that justice,\\nBut that he wakens it up with regreemory,\\nAnd please the hopeful accusden, who\\nrather set down out the rest:\\nAppeal all your person be hurl'd,\\nLandary, he should to hold me how\\nThat bears most part in a dearer deed desert:\\nif, not, thus. Ky'll that alike your people\\nUntil Gon' seen him that is not high'd to seat it.\\n\\nDUKE OF AUMERLE:\\nWith saints dore worthy eare brine I stood away.\\n\\nRICHA\"\n",
            " b\"ROMEO:\\nGo, this my man stand by; and must not when\\nyou ran a royal grace to take or dead; do not studied you\\nHalf all the day that hath always boy\\nHow you have said for the most dim countening hate;\\nThy tempest thich she hath ever bear my wound.\\n\\nRIVERS:\\nOr yet he hate, his book! and like a catch;\\nWhich first I did thence; to end those magest,\\nWhich as our sons, forbids the weakeness\\nof a great earm, that will say you thank;\\nThough I child eyes, nor, old now wear out for\\nmouth: I will hence and nid the world as warrant.\\n\\nLEONTES:\\nTo tresh friar, the Duke of York thee with thy power,\\nBut life to sit and cell him fear their houses!\\nYou have none stood, my husband, any thing upon my heart,\\nWhich, by a highin bleasiegers in this presence,\\nAnd consorted with worthy Edward's land;\\nWho were no lets ir pale eighter'd shame,\\nAs overyeld eyes drugh make the furthest sea,\\nRequainted her; with a man that's nothing,\\nOur few drops King in dest on his hates.\\nWhy, was my father died and sure\\nIs never to him\"\n",
            " b\"ROMEO:\\nGod muster up some time. Prove misactires of the silly,\\nI have well'd to angel out a\\nbatterly consent in sins and pray.\\nIt is, much more tormentsmen with thing to more\\nThan twine and suffer, and at libble and all!\\nCome on, could never Bring back profitious,\\nand my chipper, dry too noble;\\nSpeak free from seeming steep; when you should do,\\nbach, by this token, sound all fastime at my request;\\nOur knee be bluet, whose sudden came I hope,\\nWhich else would show me on this precious stund,\\nThat King Lewis from this five subject thus pector'?\\nThou dost, and, so which I for an you all:\\nThe day how sweet Juliett lives a necklessed, strength, I know\\nnot when my oath wrong'd their own chats, by her old\\nAs save your recreence; but where down moting heir\\nAnd he should fear their works without the name of Goo,\\nThat I encause two incornsect Margere\\nThe Englis man then have raised to fill him maid\\nThe Duke of Norfolk fall along with bitterest;\\nAnd cheers our noble keep and wedded merdeterms,\\nShall ans\"\n",
            " b\"ROMEO:\\nDost thou forget the more, and so that that?\\n\\nTRANIO:\\nIf I go so?\\n\\nPETRUCHIO:\\nThe countenance seems, twenty thousand, mock'd lowers and\\nthe day of foes than wo\\ndream him from whence to Lamentia it day.\\n\\nHERMIONE:\\nYou have rend asked him at once pholloo stabe at Lucit,\\nSome two of grief makes to do instant:\\nBut wherefore heaven is outrage, live in thy mind\\nUnshown'd for away or straw, tell me how I\\nlose shed to knowledge the next high-like for our death,\\nTo the dewer in half by usuraller,\\nOr wilt thou love peril'd in another sie,\\nWhich else believed, I did not wish'd\\nUpon the which he house a prize; next,\\nAn enmity as the king and private\\nprescamonger.\\n\\nShepherd:\\nLeave the king, what of that?\\nHere, take that, take not your knee but mine:\\nI will not marry yet; and here I head on't.\\nIf not, thou art a traitor to the branch\\nDemory I had aspish it in scorn, were you\\nVillating, a ruttle just ceremonize; and leave thyself\\nthat from thine own pardon, and robes not the while,\\nWill none of thos\"\n",
            " b\"ROMEO:\\n\\nProvost:\\n\\nPriest:\\nA ray, as you have undoned! I now all,\\nFor what did under thire prancties and Lord Arrian\\nLesser twing, with mine arm, one\\nLoud's to be this chain;\\nAnd Senators, &Chard's wife no more ashoral of Willsies.\\nHow does your queen? pluck out again.\\n\\nPERDITA:\\nSo you me, shall I not, Pompey; govern'd\\nThe shepherd's steel, take the queen therewith.\\nI will not pass the make thou camest of woe;'\\nAppoyards to the people, how speed you\\nTo think my mange have ta' none of our dufe and his state:\\nEither his father's houses having Montague;\\nThe roof you have whether I should post but mine own,\\nWhen we have corrupting you in Time,\\nHat him no more are we and told him off,\\nProclaim language; more after this unto take,\\nSlaughter'd in this royal tedious! what is the right day.\\n\\nLUCIO:\\n\\nISABELLA:\\nPart us this recelfio-manterous sentence of my hand:\\nWhich was as lancel in his earth?\\n\\nSecond Keeper:\\nI'll go along with the fall of ruin-wases; why the nature will\\nwithin, deaf, and still begga\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 8.59291696548462\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNtj5z4ZpJNW",
        "outputId": "b67476ae-140e-4c76-80b2-30fd89249a28"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x79ed4eb40340>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step') # untuk menyimpan objek one_step_model ke dalam format SavedModel. \n",
        "one_step_reloaded = tf.saved_model.load('one_step') # untuk memuat kembali model yang telah disimpan sebelumnya. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuupJAS1pKhH",
        "outputId": "52f61ebe-2e43-4750-d8b5-ba2bd69786de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "O, what is it?\n",
            "\n",
            "GLOUCESTER:\n",
            "Here!\n",
            "Saint whom here I mistrust now what you sought.\n",
            "\n",
            "GLOUCESTER:\n",
            "How!\n"
          ]
        }
      ],
      "source": [
        "states = None # menginisialisasi keadaan model states menjadi None.\n",
        "next_char = tf.constant(['ROMEO:']) # menentukan karakter awal yang akan digunakan sebagai input untuk memulai generasi teks.\n",
        "result = [next_char] # membuat daftar result yang akan menyimpan urutan karakter yang dihasilkan selama generasi teks.\n",
        "\n",
        "for n in range(100): # loop sebanyak 100 langkah untuk melakukan generasi teks.\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states) # generasi teks \n",
        "  result.append(next_char) # Karakter yang diprediksi selanjutnya ditambahkan ke dalam daftar result.\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\")) # mencetak hasil generasi teks."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
