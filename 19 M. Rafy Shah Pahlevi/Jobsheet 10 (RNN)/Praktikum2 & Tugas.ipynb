{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eljfdS80hI7"
      },
      "source": [
        "### Praktikum 2\n",
        "Generator Teks dengan RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIYiUUrY0hJD"
      },
      "outputs": [],
      "source": [
        "# Import library\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAdyBavd0hJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e81588a-066e-470d-cc08-65c06fdde1b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_file=tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21dZSZ5Y0hJI",
        "outputId": "79d53026-c7a5-4a26-f709-87a0851d2dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UbwTz4r0hJM",
        "outputId": "335e50ad-c891-4a61-bcc1-d312f57145df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-kbGSHT0hJN"
      },
      "source": [
        "### Olah Teks\n",
        "Vectorize Teks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdvlaP1T0hJO"
      },
      "outputs": [],
      "source": [
        "# contoh teks yang akan dipecah menjadi karakter\n",
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "# pecah setiap teks menjadi karakter menggunakan encoding UTF-8\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlOOaEyb0hJO"
      },
      "outputs": [],
      "source": [
        "# buat layer StringLookup untuk mengonversi karakter ke ID\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzpBgOng0hJP",
        "outputId": "87c92ec3-481a-4b36-a0f5-6e33b96060f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Menggunakan layer StringLookup untuk mengonversi karakter menjadi ID\n",
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6xBJrlE0hJR"
      },
      "outputs": [],
      "source": [
        "# buat layer StringLookup untuk mengonversi ID kembali ke karakter\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvdrniDu0hJS",
        "outputId": "d0096d5e-4cca-4377-b43a-bc700c534362"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "chars=chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHJQOwnZ0hJU"
      },
      "outputs": [],
      "source": [
        "# menggabungkan karakter-karakter menjadi teks menggunakan reduce_join\n",
        "tf.strings.reduce_join(chars, axis=-1).numpy()\n",
        "\n",
        "# fungsi untuk mengonversi ID menjadi teks\n",
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLHyNATB0hJW"
      },
      "source": [
        "### Prediksi\n",
        "Membuat Trianing Set dan Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs5Ee7wD0hJX",
        "outputId": "262e5d4e-9a87-43fc-87d5-88207ce45aeb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# mengonversi seluruh teks menjadi ID menggunakan StringLookup\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVmXpgD70hJY"
      },
      "outputs": [],
      "source": [
        "ids_dataset=tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8F45Zgl0hJZ",
        "outputId": "7657903d-7300-441e-d3a6-a14ccef3ecfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan 10 contoh teks dari dataset ID\n",
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))\n",
        "\n",
        "# Panjang urutan yang diinginkan\n",
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28KmDz7U0hJZ",
        "outputId": "ac2bf089-22fc-4ab8-aa42-c53fb71e9912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# Membuat urutan (sequences) dari dataset ID dengan panjang urutan + 1\n",
        "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
        "\n",
        "# Menampilkan satu contoh urutan\n",
        "for seq in sequences.take(1):\n",
        "    print(chars_from_ids(seq))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wahC1SSg0hJa",
        "outputId": "7756b21f-0cf1-42b2-f8e7-051f1277758e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "# menampilkan teks dari lima contoh urutan\n",
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcqA24Q00hJb"
      },
      "outputs": [],
      "source": [
        "# Fungsi untuk memisahkan teks input dan teks target dari suatu urutan\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CBOkEVm0hJc",
        "outputId": "e38ce7fc-9e87-48cb-9619-9e1171d029d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "# Memisahkan teks input dan teks target dari urutan karakter \"Tensorflow\"\n",
        "split_input_target(list(\"Tensorflow\"))\n",
        "\n",
        "# Membuat dataset dari urutan karakter dengan fungsi split_input_target\n",
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "# Menampilkan contoh input dan target dari dataset\n",
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76DA-D3N0hJd"
      },
      "source": [
        "Membuat Batch Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVuqOpY30hJd",
        "outputId": "028ad04f-44c3-4d6a-abf0-8f102561dde0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MDYDQgO0hJe"
      },
      "source": [
        "Buat Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3_uuEqj0hJf"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-_emdCN0hJg"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe6JsvLt0hJh"
      },
      "outputs": [],
      "source": [
        "# Membuat instance dari model kustom (MyModel)\n",
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyLI3w2_0hJi"
      },
      "source": [
        "Uji Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HqTCI8C0hJj",
        "outputId": "0992f079-9b7a-44d3-f6aa-969e3458a9c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODYudP-u0hJk",
        "outputId": "fea1d00c-1231-427e-b672-ad295ab9749d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSdyWNZK0hJl",
        "outputId": "25ed5055-4a92-44ae-f121-5a05869647b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'hou king, and wilt be forced?\\nI shame to hear thee speak. Ah, timorous wretch!\\nThou hast undone thys'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'cClv\\n;.nzr Xb-iDAkP3f!EuWs.GEZv\\nSfn;YDD-gGCxUJSZKUu&-i$pa.gXsB?[UNK]bd$DNAM:WHoolooLX:P $VjHJZUbrQ-\\niO[UNK]C'\n"
          ]
        }
      ],
      "source": [
        "# Menghasilkan indeks sampel dengan menggunakan distribusi kategori acak\n",
        "sampled_indices=tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices= tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices\n",
        "\n",
        "print(\"Input:\\n\",text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQrR0Uf_0hJl"
      },
      "source": [
        "Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoEo6TXK0hJm"
      },
      "source": [
        "Tambahan optimizer dan fungsi loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MztYKNHy0hJn"
      },
      "outputs": [],
      "source": [
        "# Membuat fungsi loss menggunakan Sparse Categorical Crossentropy\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO-Pyuhk0hJo",
        "outputId": "e10fdb8e-1be9-4954-dca5-8cab104205cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.189146, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Menghitung rata-rata loss menggunakan Sparse Categorical Crossentropy\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "596QVzOV0hJo"
      },
      "outputs": [],
      "source": [
        "# Menghitung nilai eksponensial dari rata-rata kerugian\n",
        "tf.exp(example_batch_mean_loss).numpy()\n",
        "# Mengompilasi model dengan optimizer Adam\n",
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmJOd7Sh0hJp"
      },
      "source": [
        "Konfigurasi Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVnc8Tru0hJq"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn_L5mNu0hJr"
      },
      "source": [
        "Lakukan Proses Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfhrbGAa0hKH",
        "outputId": "7cfbcd6b-434c-49d4-c007-20b0ee2c01d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 17s 56ms/step - loss: 2.7349\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 13s 56ms/step - loss: 2.0033\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 13s 60ms/step - loss: 1.7221\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 15s 60ms/step - loss: 1.5602\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 1.4600\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 1.3898\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 1.3362\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 1.2920\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.2517\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 13s 59ms/step - loss: 1.2123\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 16s 65ms/step - loss: 1.1729\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 15s 60ms/step - loss: 1.1328\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 13s 61ms/step - loss: 1.0906\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 1.0463\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 0.9995\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 0.9493\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 0.8975\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 13s 60ms/step - loss: 0.8457\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 13s 60ms/step - loss: 0.7940\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 13s 59ms/step - loss: 0.7438\n"
          ]
        }
      ],
      "source": [
        "# Jumlah epoch yang diinginkan\n",
        "EPOCHS = 20\n",
        "\n",
        "# Melatih model dengan dataset dan callback untuk menyimpan checkpoint\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v67jTapN0hKJ"
      },
      "source": [
        "Generate Teks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVGsbJVr0hKL"
      },
      "outputs": [],
      "source": [
        "# Definisi class OneStep\n",
        "class OneStep(tf.keras.Model):\n",
        "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.model = model\n",
        "        self.chars_from_ids = chars_from_ids\n",
        "        self.ids_from_chars = ids_from_chars\n",
        "\n",
        "        skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "        sparse_mask = tf.SparseTensor(\n",
        "            # Meletakkan -inf pada setiap indeks yang tidak diinginkan.\n",
        "            values=[-float('inf')] * len(skip_ids),\n",
        "            indices=skip_ids,\n",
        "            # Sesuaikan bentuk dengan kosakata\n",
        "            dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "    @tf.function\n",
        "    def generate_one_step(self, inputs, states=None):\n",
        "        # Mengonversi string menjadi token ID.\n",
        "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "        # Menjalankan model.\n",
        "        # Bentuk predicted_logits adalah [batch, char, next_char_logits]\n",
        "        predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                              return_state=True)\n",
        "        # Hanya menggunakan prediksi terakhir.\n",
        "        predicted_logits = predicted_logits[:, -1, :]\n",
        "        predicted_logits = predicted_logits / self.temperature\n",
        "        # Terapkan mask prediksi\n",
        "        predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "        # Ambil sampel token ID keluaran.\n",
        "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "        # Mengonversi dari token ID menjadi karakter.\n",
        "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "        # Mengembalikan karakter dan state model.\n",
        "        return predicted_chars, states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFJ3X7Yw0hKO"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzKhVQSq0hKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b195bda4-8e33-43cc-88d7-86e00a659acd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "But had he died, and many a match.\n",
            "\n",
            "MERCUTIO:\n",
            "And, by God's!\n",
            "\n",
            "COMINIUS:\n",
            "Ho! no word.\n",
            "\n",
            "AUFODYCUS:\n",
            "I had a bady school-dangerous lie!\n",
            "Camills fantagenet, and the bear most unnatural aid\n",
            "And crows too talk alone: let this cliff;\n",
            "Lead this safetial, and importuned men\n",
            "As poist or women: every sorrow has the king's,\n",
            "And give us not, too fair and very shot.\n",
            "\n",
            "LUCIO:\n",
            "Well, I must I had slain Lewis' to Calling means:\n",
            "To be so ruled, to pluck all former lands,\n",
            "I'll make the ears, and some care.\n",
            "\n",
            "Gardenes: let\n",
            "them by the house: where I should not be sleeps?\n",
            "\n",
            "TRANIO:\n",
            "Was ever follow'd this before you well?\n",
            "\n",
            "LUCIO:\n",
            "That's the heart that cannot do it.\n",
            "\n",
            "ESCALUS:\n",
            "Everyore, sir! none.\n",
            "\n",
            "PETRUCHIO:\n",
            "You have a bard air of me, my sword in the\n",
            "disguision of us thus I buckle,\n",
            "We'll much ever up to strike? it may enter\n",
            "And over all discord lain with subs and will not\n",
            "Come hither: sirs, content a tale, sir.\n",
            "\n",
            "FLORIZEL:\n",
            "My boy,\n",
            "Done gift than feet to this new marmless in his errand;\n",
            "My way is the younger deepl \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.3391544818878174\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4gYdPy00hKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421f721d-c3e3-4202-dd35-608ecbe2c2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nThou shouldst have marriage now,\\nWhom I, by repeal, my his own life and mine\\nShall rest with traitor, provost; and myself\\nBonest in earnestness to's throats of time,\\nSome are by Romeo, to see thee all.\\n\\nBIONDELLO:\\nI give you in you, sir; I'll not be so bad and a cold;\\nAnd this before my good sister, but my sovereign\\nknels a miserable sly; only to be Lond of Grounca,\\nWhich severeivy to subscurns! I am too so.\\n\\nKING RICHARD III:\\nKind conforn, my brother brings the triumph day.\\n\\nDUKE OF AUMERLE:\\nFor my ware do London with that stones at will make his mother\\nshould be talked for better at that counsel in the scene.\\nHark ye, and be the better.\\n\\nMy needs you are we sword spirit to Lodd of George,\\nAnd thou some queen's are the night is dege.\\n\\nSLY:\\nI am could never welcome a. Behold, this troable to hear\\nAs I am a most needful briteful body.\\n\\nVIRGILIA:\\nSir, a little me, encounted, as it were Mistress;\\nAnd Mercutio's dead likes, under laug-heather,\\nHath nothing discharge tyrel, for their heads\"\n",
            " b\"ROMEO:\\nThe prince and peward will is mine shall die.\\n\\nLUCIO:\\nDo not sanct, too worship.\\n\\nCORIOLANUS:\\nYou'll give you ever stand up.\\n\\nDUKE VINCENTIO:\\nWhen doth he comes?\\nAway befall'n and uncle Glounes,\\nWith tears despair against my Edward both mine.\\nDo't--you may partake to death that nature made kings\\nOf embraces night, for your ears a King of March,\\nTrail thither--good royalty:\\nWith thy bless deserves of men and\\nthe hand is, depart death: but ill-wis dong,\\nHave they to be their bed: so tedious is\\nthis fashion might have trouble thee my fell worm\\nNot disdain; such as steps or by Paulina should\\nenter, anone-broker. I love the maid here.\\n\\nServant:\\nMy lady and you now; I am out my son;\\nSo since we were allought ever read and justice:\\nAnd so dells we higher with the Aufidius.\\n\\nJULIET:\\nGo, get thee gone, and will deserve no guilty:\\nNothing but revenge, triam might have more beat!\\nA plague upon my supper, that hath take my leave,\\nAnd pit upon your executioner?\\n\\nGLOUCESTER:\\nThen thou hast made me \"\n",
            " b\"ROMEO:\\nThis was the belly, my mother, mowing-dance,\\nOf the devil that hath no wretched plage.\\nDidst tender you?\\n\\nLEONTES:\\nNot sink in manifest? and are you see't\\nto be the dissinon of the middle\\nOn the ground should know of gentlewomen four dry.\\nFirst welcome with him, black my oatch at me;\\nAnd put thy queen gave him that should enter.\\n\\nROMEO:\\nThou know'st a knife in dead men's state,\\nWhich grieves me well affection's manGul\\nA sea and lands unto me with the\\npull, she's demanded. O, thou hasted, let her hence;\\nIf she your fellow had but lately in the heart\\nThat can my old be ready, took some, and it\\nnot trust you; 'Wil Prince about him for her company.\\n\\nWARWICK:\\nSome sing and Clarence; thou coll'd the soldiers' looks,\\nWhereby they lie: but that I begin to serve,\\nBoth to desire upon this present.\\nAnd wilt thou make a small knee--\\nThat I might courtesy, if you be mother,\\nBut by your lives if thou Romans as it is.\\nNow seems to be to be the fastles were but sovereignty.\\nNow, for my lord, the Wolv\"\n",
            " b\"ROMEO:\\nThou hadst an evil day so sweet to me.\\n\\nTRANIO:\\nWhy follow is the fair grey'd to talk and make\\nHis parliament or death with dun this distamp,\\nShe spiles not with the helmets of our wealts.\\n\\nGREGORY:\\nI saw him wrong and not so, my request\\nWill break his new spring-prayed in mine ele:\\nBe sometime deadly straight drip 'TESTAR: if his great game that I may glave\\nHerself purpose and beauty with our eyes.\\nThese remains absent in his quaintle lunn,\\nAnd advensure of his supper-full of battle; they strike from me\\nThat seesing to this practs by,\\nHark on we go thyself and in a wing. Their beauty outs,\\nThat, will you not; Go, say I am then been;\\nFor, to defend my rude lay on mine ease my extremest?\\nYou are thou shalt ne'er wanteth with a husband!\\nMy fair sad son,--Holk you, I see, as thou dost fors,\\nHeartiest was do eater. All that comest thou hither\\nFor warm'd with termseth and air will stand to\\nus for that as you are, a rankard knows not.\\n\\nHERMIONE:\\nA good daughter were that thou knowest not\\nTo\"\n",
            " b\"ROMEO:\\nThe loss you will rest. Come on, break, or was, my false trib.\\nBut, as my sweet slieps o' the carelessly?\\n\\nLUCIO:\\nWhy look you shall hear me?\\n\\nCAPULET:\\nDost thou draw the manhood is curses bud successes.\\n\\nESCALUS:\\nBrenk your deep and danger; in despaiding\\ndeath. O foul inamplace\\nOf grief shall see, thine comes by the year;\\nAnd by my father's body was nothing;\\nBut, good strokes, tradession with such fellows:\\nSo dear with him that she shall think it not\\ntowards far asleep.\\n\\nProvost:\\nAs mine own life, the devil tears said as\\nthis sentence.\\n\\nLEONTES:\\nHow long I am here?\\nWe'll talk but this an adulteress.\\n\\nSIVINGHAM:\\nI call'd thee my report: I mean, my looks,\\nSuppect a fearful black shades,\\nTo hear this kentel mocked a thorn beauty's maid:\\nSpeak with my heart, break from the old men's extreation.\\n\\nDUKE OF YORK:\\nWelcome! a puit a fye.\\n\\nLADY CAPULET:\\nA cuckal, content till avoid the search\\nOf the enemy--kending thereby\\nWhich he so sets his use and welcome time\\nWhen I am fulf. His sware as ev\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE5x0URY0hKa"
      },
      "source": [
        "Ekspor Model Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SahozWSA0hKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b13484-d092-4ba2-f508-b7f14173d5cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7c8c181ebc10>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDtv8Kiu0hKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a507c4-fcdf-4ba7-dc7b-0d775fb6f605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Well, by my mistress, pardon, we'll not push death;\n",
            "And thou didst kill the king and that I may not\n"
          ]
        }
      ],
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tugas**\n",
        "\n",
        "Prosedur pelatihan pada praktikum 2 merupakan prosedur sederhana, yang tidak memberi Anda banyak kendali. Model ini menggunakan \"teacher-forcing\" yang mencegah prediksi buruk diumpankan kembali ke model, sehingga model tidak pernah belajar untuk pulih dari kesalahan. Jadi, setelah Anda melihat cara menjalankan model secara manual, selanjutnya Anda akan mengimplementasikan custom loop pelatihan. Hal ini memberikan titik awal jika, misalnya, Anda ingin menerapkan pembelajaran kurikulum untuk membantu menstabilkan keluaran open-loop model. Bagian terpenting dari loop pelatihan khusus adalah fungsi langkah pelatihan.\n",
        "\n",
        "Gunakan tf.GradientTape untuk men track nilai gradient. Anda dapat mempelajari lebih lanjut tentang pendekatan ini dengan membaca eager execution guide.\n",
        "\n",
        "Prosedurnya adalah \"\n",
        "\n",
        "1. Jalankan Model dan hitung loss dengan tf.GradientTape.\n",
        "\n",
        "2. Hitung update dan terapkan pada model dengan optimizer"
      ],
      "metadata": {
        "id": "B0Eqx16V4TYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendefinisikan class CustomTraining yang merupakan turunan dari MyModel\n",
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "      inputs, labels = inputs\n",
        "      with tf.GradientTape() as tape:\n",
        "          predictions = self(inputs, training=True)\n",
        "          loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ],
      "metadata": {
        "id": "-dtHJL-R4eXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode diatas menerapkan train_step method sesuai dengan  Keras' train_step conventions. Ini opsional, tetapi memungkinkan Anda mengubah perilaku langkah pelatihan dan tetap menggunakan keras Model.compile and Model.fit methods."
      ],
      "metadata": {
        "id": "9Gxju_wX4pEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat instance dari kelas CustomTraining\n",
        "model = CustomTraining(\n",
        "\n",
        "    # Menentukan ukuran kosakata (vocab_size) berdasarkan panjang kosakata yang dihasilkan oleh ids_from_chars.get_vocabulary()\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "\n",
        "    # Menentukan dimensi embedding (embedding_dim) untuk lapisan embedding model\n",
        "    embedding_dim=embedding_dim,\n",
        "\n",
        "    # Menentukan jumlah unit dalam lapisan GRU (rnn_units) pada model\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "PH3U0KPm4p9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengompilasi model dengan pengoptimal Adam dan fungsi loss Sparse Categorical Crossentropy\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        ")"
      ],
      "metadata": {
        "id": "ZNjFbZ8O4wyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan dataset untuk satu epoch\n",
        "model.fit(dataset, epochs=1)"
      ],
      "metadata": {
        "id": "VSNClJGP4yvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cafa747f-1749-4166-e257-71e74faf4c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172/172 [==============================] - 14s 60ms/step - loss: 2.7308\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c8be0262680>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Atau jika ingin lebih mengetahui dalamnya, kita bisa membuat custom training loop sendiri:"
      ],
      "metadata": {
        "id": "5GFQhks-42EL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jumlah epoch yang diinginkan\n",
        "EPOCHS = 10\n",
        "\n",
        "# Inisialisasi mean untuk menghitung rata-rata loss\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "# Melakukan iterasi melalui epoch\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    # Mengatur ulang state mean\n",
        "    mean.reset_states()\n",
        "\n",
        "    # Melakukan iterasi melalui batch-batch dalam dataset\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "        # Memperbarui state dan mendapatkan logs dari model.train_step\n",
        "        logs = model.train_step([inp, target])\n",
        "        mean.update_state(logs['loss'])\n",
        "\n",
        "        # Menampilkan informasi setiap 50 batch\n",
        "        if batch_n % 50 == 0:\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "            print(template)\n",
        "\n",
        "    # Menyimpan (checkpoint) model setiap 5 epoch\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "# Menyimpan berat model setelah selesai pelatihan\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ],
      "metadata": {
        "id": "7ac1Omgj42lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c533fa-878d-4d4c-81d6-8e1074700269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1438\n",
            "Epoch 1 Batch 50 Loss 2.0615\n",
            "Epoch 1 Batch 100 Loss 1.9403\n",
            "Epoch 1 Batch 150 Loss 1.8454\n",
            "\n",
            "Epoch 1 Loss: 1.9991\n",
            "Time taken for 1 epoch 13.15 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.8367\n",
            "Epoch 2 Batch 50 Loss 1.7609\n",
            "Epoch 2 Batch 100 Loss 1.6990\n",
            "Epoch 2 Batch 150 Loss 1.7070\n",
            "\n",
            "Epoch 2 Loss: 1.7285\n",
            "Time taken for 1 epoch 11.70 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.5993\n",
            "Epoch 3 Batch 50 Loss 1.6000\n",
            "Epoch 3 Batch 100 Loss 1.5387\n",
            "Epoch 3 Batch 150 Loss 1.5154\n",
            "\n",
            "Epoch 3 Loss: 1.5677\n",
            "Time taken for 1 epoch 12.33 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4476\n",
            "Epoch 4 Batch 50 Loss 1.4889\n",
            "Epoch 4 Batch 100 Loss 1.4579\n",
            "Epoch 4 Batch 150 Loss 1.3921\n",
            "\n",
            "Epoch 4 Loss: 1.4661\n",
            "Time taken for 1 epoch 12.53 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.4067\n",
            "Epoch 5 Batch 50 Loss 1.3653\n",
            "Epoch 5 Batch 100 Loss 1.4436\n",
            "Epoch 5 Batch 150 Loss 1.3628\n",
            "\n",
            "Epoch 5 Loss: 1.3962\n",
            "Time taken for 1 epoch 11.91 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3322\n",
            "Epoch 6 Batch 50 Loss 1.3507\n",
            "Epoch 6 Batch 100 Loss 1.3399\n",
            "Epoch 6 Batch 150 Loss 1.3572\n",
            "\n",
            "Epoch 6 Loss: 1.3428\n",
            "Time taken for 1 epoch 11.13 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2880\n",
            "Epoch 7 Batch 50 Loss 1.3021\n",
            "Epoch 7 Batch 100 Loss 1.3052\n",
            "Epoch 7 Batch 150 Loss 1.3248\n",
            "\n",
            "Epoch 7 Loss: 1.2971\n",
            "Time taken for 1 epoch 11.15 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2164\n",
            "Epoch 8 Batch 50 Loss 1.2199\n",
            "Epoch 8 Batch 100 Loss 1.2945\n",
            "Epoch 8 Batch 150 Loss 1.2775\n",
            "\n",
            "Epoch 8 Loss: 1.2562\n",
            "Time taken for 1 epoch 20.47 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.2299\n",
            "Epoch 9 Batch 50 Loss 1.2140\n",
            "Epoch 9 Batch 100 Loss 1.1892\n",
            "Epoch 9 Batch 150 Loss 1.2209\n",
            "\n",
            "Epoch 9 Loss: 1.2175\n",
            "Time taken for 1 epoch 12.20 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1675\n",
            "Epoch 10 Batch 50 Loss 1.1726\n",
            "Epoch 10 Batch 100 Loss 1.1741\n",
            "Epoch 10 Batch 150 Loss 1.2032\n",
            "\n",
            "Epoch 10 Loss: 1.1784\n",
            "Time taken for 1 epoch 11.64 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jalankan kode diatas dan sebutkan perbedaanya dengan praktikum 2?"
      ],
      "metadata": {
        "id": "Zn62kF2j5I0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perbandingan:**\n",
        "\n",
        "- Potongan kode di Tugas memberikan lebih banyak kendali kepada pengguna untuk menyesuaikan model dan pelatihan. Potongan kode di Praktikum 2 lebih mudah digunakan karena menyediakan fitur-fitur terintegrasi yang siap pakai.\n",
        "- Potongan kode di Tugas dapat membantu pengguna memahami cara kerja setiap langkah dalam pelatihan. Potongan kode di Praktikum 2 lebih fokus pada pemakaian yang lebih mudah dan efisien."
      ],
      "metadata": {
        "id": "v-0yNrDlyCvd"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}