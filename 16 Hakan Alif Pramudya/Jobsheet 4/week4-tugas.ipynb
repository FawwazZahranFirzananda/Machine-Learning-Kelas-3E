{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Buatlah model klasifikasi dengan menggunakan SVM untuk data suara, `voice.csv`. \n",
    "2. Buatlah model klasfikasi Multinomial Naive Bayes dengan ketentuan,\n",
    "    1. Menggunakan data `spam.csv`\n",
    "    2. Fitur `CountVectorizer` dengan mengaktifkan **stop_words**\n",
    "    3. Evaluasi hasilnya\n",
    "3. Buatlah model klasfikasi Multinomial Naive Bayes dengan ketentuan,\n",
    "    1. Menggunakan data `spam.csv`\n",
    "    2. Fitur `TF-IDF` dengan mengaktifkan **stop_words**\n",
    "    3. Evaluasi hasilnya dan bandingkan dengan hasil pada Tugas no 2.\n",
    "    4. Berikan kesimpulan fitur mana yang terbaik pada kasus data `spam.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Buatlah model klasifikasi dengan menggunakan SVM untuk data suara, `voice.csv`. \n",
    "\n",
    "# import library\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('voice.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, 0:20]\n",
    "y = data.iloc[:,20]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "m = SVC(kernel='linear', C=1)\n",
    "m = m.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male', 'male', 'female', 'female', 'female', 'male', 'male',\n",
       "       'female', 'female', 'male', 'female', 'male', 'male', 'male',\n",
       "       'male', 'female', 'female', 'male', 'female', 'female', 'female',\n",
       "       'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male',\n",
       "       'male', 'male', 'female', 'male', 'male', 'female', 'male', 'male',\n",
       "       'male', 'female', 'male', 'female', 'male', 'female', 'male',\n",
       "       'female', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'female', 'female', 'female', 'male',\n",
       "       'male', 'female', 'female', 'female', 'female', 'female', 'female',\n",
       "       'male', 'male', 'female', 'male', 'female', 'female', 'female',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'female', 'female', 'female', 'female',\n",
       "       'female', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'female', 'female', 'male', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'female', 'female', 'female', 'male', 'male',\n",
       "       'male', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "       'female', 'male', 'female', 'male', 'male', 'male', 'female',\n",
       "       'female', 'male', 'female', 'male', 'male', 'male', 'male',\n",
       "       'female', 'female', 'male', 'male', 'male', 'female', 'female',\n",
       "       'female', 'female', 'female', 'female', 'female', 'male', 'male',\n",
       "       'male', 'male', 'male', 'female', 'female', 'female', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'female', 'female', 'female', 'male', 'male', 'male', 'female',\n",
       "       'male', 'female', 'male', 'male', 'female', 'female', 'female',\n",
       "       'female', 'male', 'male', 'female', 'male', 'male', 'female',\n",
       "       'female', 'female', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'female', 'female', 'male', 'male', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'female', 'male',\n",
       "       'female', 'female', 'male', 'female', 'male', 'male', 'male',\n",
       "       'female', 'male', 'female', 'female', 'female', 'female', 'female',\n",
       "       'male', 'female', 'male', 'male', 'female', 'male', 'female',\n",
       "       'male', 'male', 'female', 'female', 'male', 'female', 'female',\n",
       "       'male', 'female', 'female', 'male', 'female', 'female', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'female', 'male', 'male', 'female', 'female',\n",
       "       'female', 'male', 'male', 'female', 'female', 'female', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'female', 'male', 'female', 'female', 'female',\n",
       "       'male', 'female', 'female', 'male', 'female', 'male', 'female',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'female', 'female', 'female', 'female', 'male',\n",
       "       'female', 'male', 'female', 'male', 'male', 'male', 'male',\n",
       "       'female', 'female', 'female', 'female', 'male', 'male', 'female',\n",
       "       'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male',\n",
       "       'male', 'female', 'male', 'female', 'male', 'male', 'male', 'male',\n",
       "       'male', 'female', 'male', 'female', 'male', 'female', 'female',\n",
       "       'female', 'male', 'female', 'male', 'male', 'female', 'female',\n",
       "       'male', 'female', 'female', 'female', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'male', 'female',\n",
       "       'female', 'male', 'female', 'male', 'female', 'male', 'male',\n",
       "       'female', 'female', 'female', 'male', 'male', 'female', 'female',\n",
       "       'male', 'male', 'female', 'female', 'female', 'male', 'female',\n",
       "       'male', 'female', 'male', 'female', 'male', 'female', 'male',\n",
       "       'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'female', 'female',\n",
       "       'female', 'male', 'female', 'female', 'male', 'female', 'male',\n",
       "       'male', 'male', 'female', 'male', 'female', 'female', 'male',\n",
       "       'male', 'female', 'male', 'male', 'female', 'female', 'male',\n",
       "       'female', 'male', 'female', 'male', 'male', 'male', 'male',\n",
       "       'female', 'female', 'female', 'male', 'male', 'female', 'female',\n",
       "       'male', 'male', 'female', 'female', 'male', 'male', 'male',\n",
       "       'female', 'male', 'female', 'male', 'female', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male',\n",
       "       'male', 'female', 'female', 'female', 'male', 'female', 'female',\n",
       "       'female', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'female', 'male', 'female',\n",
       "       'male', 'male', 'male', 'female', 'male', 'male', 'female',\n",
       "       'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'female', 'male', 'female', 'male', 'female',\n",
       "       'male', 'female', 'female', 'female', 'female', 'male', 'male',\n",
       "       'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male',\n",
       "       'female', 'female', 'male', 'male', 'male', 'male', 'female',\n",
       "       'male', 'male', 'male', 'male', 'female', 'female', 'female',\n",
       "       'male', 'female', 'male', 'female', 'male', 'male', 'male', 'male',\n",
       "       'male', 'female', 'female', 'female', 'female', 'female', 'male',\n",
       "       'male', 'male', 'male', 'female', 'male', 'male', 'female',\n",
       "       'female', 'male', 'male', 'female', 'male', 'male', 'male', 'male',\n",
       "       'female', 'female', 'female', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'female', 'male', 'female', 'female',\n",
       "       'male', 'male', 'male', 'male', 'female', 'male', 'female',\n",
       "       'female', 'female'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = m.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9290220820189274\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Buatlah model klasfikasi Multinomial Naive Bayes dengan ketentuan,\n",
    "#    1. Menggunakan data `spam.csv`\n",
    "#    2. Fitur `CountVectorizer` dengan mengaktifkan **stop_words**\n",
    "#    3. Evaluasi hasilnya\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "data2 = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "data2 = data2.drop(data2.iloc[:,2:], axis=1)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Labels                                                SMS\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cols = {\n",
    "    'v1': 'Labels',\n",
    "    'v2': 'SMS'\n",
    "}\n",
    "\n",
    "# Rename nama kolom v1 dan v2\n",
    "data2 = data2.rename(columns=new_cols)\n",
    "\n",
    "# cek data\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Labels                                                SMS\n",
       "0       0  Go until jurong point, crazy.. Available only ...\n",
       "1       0                      Ok lar... Joking wif u oni...\n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       0  U dun say so early hor... U c already then say...\n",
       "4       0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data untuk label\n",
    "new_labels = {\n",
    "    'spam': 1,\n",
    "    'ham': 0\n",
    "}\n",
    "\n",
    "# Encode label\n",
    "data2['Labels'] = data2['Labels'].map(new_labels)\n",
    "\n",
    "# Cek data\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi: 0.9838565022421525\n",
      "\n",
      "Laporan Klasifikasi:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       965\n",
      "           1       0.96      0.92      0.94       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.96      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "\n",
      "Matriks Konfusi:\n",
      "[[959   6]\n",
      " [ 12 138]]\n"
     ]
    }
   ],
   "source": [
    "x = data2['SMS'].values\n",
    "y = data2['Labels'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Menggunakan CountVectorizer untuk mengonversi teks menjadi representasi\n",
    "# numerik yang dapat digunakan oleh model Naive Bayes.\n",
    "# Aktifkan stop_words untuk menghilangkan kata-kata umum (stop words).\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "x_train_vectorized = vectorizer.fit_transform(x_train)\n",
    "x_test_vectorized = vectorizer.transform(x_test)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(x_train_vectorized, y_train)\n",
    "\n",
    "# Prediksi pada data uji\n",
    "y_pred = nb_model.predict(x_test_vectorized)\n",
    "\n",
    "# Menghitung akurasi\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Akurasi:\", accuracy)\n",
    "\n",
    "# Menampilkan laporan klasifikasi\n",
    "print(\"\\nLaporan Klasifikasi:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Menampilkan matriks konfusi\n",
    "print(\"\\nMatriks Konfusi:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi dengan TF-IDF: 0.97847533632287\n",
      "\n",
      "Laporan Klasifikasi dengan TF-IDF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.97      0.87      0.92       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "\n",
      "Matriks Konfusi dengan TF-IDF:\n",
      "[[961   4]\n",
      " [ 20 130]]\n"
     ]
    }
   ],
   "source": [
    "# 3. Buatlah model klasfikasi Multinomial Naive Bayes dengan ketentuan,\n",
    "#    1. Menggunakan data `spam.csv`\n",
    "#    2. Fitur `TF-IDF` dengan mengaktifkan **stop_words**\n",
    "#    3. Evaluasi hasilnya dan bandingkan dengan hasil pada Tugas no 2.\n",
    "#    4. Berikan kesimpulan fitur mana yang terbaik pada kasus data `spam.csv`\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Menggunakan TF-IDF Vectorizer untuk mengonversi teks menjadi representasi\n",
    "# TF-IDF numerik yang dapat digunakan oleh model Naive Bayes.\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "x_train_tfidf = tfidf_vectorizer.fit_transform(x_train)\n",
    "x_test_tfidf = tfidf_vectorizer.transform(x_test)\n",
    "\n",
    "# latih model yang diatas\n",
    "nb_model2 = MultinomialNB()\n",
    "nb_model2.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# Prediksi pada data uji\n",
    "y_pred_tfidf = nb_model.predict(x_test_tfidf)\n",
    "\n",
    "# Menghitung akurasi\n",
    "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "print(\"Akurasi dengan TF-IDF:\", accuracy_tfidf)\n",
    "\n",
    "# Menampilkan laporan klasifikasi\n",
    "print(\"\\nLaporan Klasifikasi dengan TF-IDF:\")\n",
    "print(classification_report(y_test, y_pred_tfidf))\n",
    "\n",
    "# Menampilkan matriks konfusi\n",
    "print(\"\\nMatriks Konfusi dengan TF-IDF:\")\n",
    "print(confusion_matrix(y_test, y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
